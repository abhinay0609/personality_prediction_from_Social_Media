{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrq2TfVfTzbInrECGLpI3F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xXkJNXr5GMzM","executionInfo":{"status":"ok","timestamp":1749664044049,"user_tz":-330,"elapsed":6062,"user":{"displayName":"Abhinay Singh","userId":"04074215444349371949"}},"outputId":"193e9826-f693-43b0-8cba-9dc2637f10f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Cleaned Tokens: ['social', 'media', 'affect', 'positive', 'nagative', 'ways']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","# Ensure NLTK is installed\n","%pip install nltk\n","# %%\n","import nltk\n","import shutil\n","import string\n","from nltk.corpus import stopwords\n","\n","# Remove the nltk_data directory to ensure a fresh download\n","# This step is okay if you want to guarantee a fresh download, but be mindful of its side effects\n","shutil.rmtree('/root/nltk_data', ignore_errors=True)\n","\n","# %%\n","# Download the required resources *after* removing the directory\n","# Force the download to ensure it happens\n","nltk.download('punkt', force=True)\n","nltk.download('stopwords', force=True)\n","\n","# %%\n","# text = \"I LOVE AI and Machine Learning!! It's so exciting.\"\n","text = \"Social Media can affect in both positive and nagative ways.\"\n","\n","# Lowercase\n","text = text.lower()\n","\n","# Remove punctuation\n","text = ''.join([char for char in text if char not in string.punctuation])\n","\n","# Tokenize using split (not word_tokenize)\n","tokens = text.split()\n","\n","# Remove stopwords\n","stop_words = set(stopwords.words('english'))\n","clean_tokens = [word for word in tokens if word not in stop_words]\n","\n","print(\"Cleaned Tokens:\", clean_tokens)"]}]}