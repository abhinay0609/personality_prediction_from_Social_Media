# personality_prediction_from_Social_Media
Internpro AI ML Internship 

This repository contains my work  for the InternPro AI/ML Internship (June 2025 - July 2025).

## ğŸ“… Week 1 Summary

- âœ… **Project Understanding** â€“ What the project is about and why it matters
- ğŸ“Š **Dataset Selection** â€“ Chose MBTI dataset (Reddit posts + personality types)   [Dataset](https://www.kaggle.com/datasets/datasnaek/mbti-type/data)
- ğŸ§¹ **Text Preprocessing** â€“ Lowercasing, punctuation removal, stopwords
- ğŸ”¢ **Feature Extraction** â€“ Applied TF-IDF using sklearn
- ğŸ“ **Logged daily progress** and prepared weekly report

## ğŸ“… Week 2 Summary

- âš™ï¸ Modeling: Tried Logistic Regression, Linear SVM, and RBF SVM
- ğŸ“Š Evaluation: Used Accuracy, Precision, Recall, F1-score
- ğŸ§  Tuning Concepts: Understood C & gamma using visual plots
- ğŸ† Best Model: RBF SVM (Balanced results & non-linear fit)

## ğŸ“… Week 3 Summary
- âš–ï¸ Performed class imbalance analysis using EDA; identified severe underrepresentation in MBTI types like ESFJ, ESTJ.
- ğŸ§¹ Applied advanced preprocessing techniques to clean and transform raw social media text more effectively.
- âš™ï¸ Implemented class_weight='balanced' in Logistic Regression, SVM, and RBF-SVM to improve fairness across rare classes.
- ğŸ“Š Achieved a notable macro F1 improvement from 0.46 â†’ 0.52 and confirmed performance boost using multiple evaluation metrics.

## Week 4 Summary
- ğŸ” Used RandomizedSearchCV to tune key hyperparameters like C and gamma for both Linear and RBF SVM.
- âš¡ Optimized models efficiently without overloading compute (used limited search space + 3-fold CV).
- âœ… Final comparison showed Logistic Regression as best with Accuracy = 0.65, Macro F1 = 0.52, Weighted F1 = 0.65.
- ğŸ“¦ Saved trained model and vectorizer using joblib for deployment in the next phase.

## Final Project Highlights / Summary
- ğŸ¤– Built an end-to-end NLP-based machine learning model to predict MBTI personality types from raw social media posts.
- ğŸ§  Explored multiple models (Logistic Regression, SVM, RBF SVM), applied class balancing, and tuned hyperparameters for fair classification.
- ğŸ“ˆ Achieved 65% accuracy and 0.52 macro F1-score with Logistic Regression â€” showing significant handling of imbalanced classes.
- ğŸ’¾ Successfully saved model artifacts (.pkl files) for future deployment (e.g., Streamlit or Flask).



